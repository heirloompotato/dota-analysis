---
title: "Dota Match Analysis"
output: github_document
---
```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## Introduction
Dota 2 is a multiplayer online battle arena (MOBA) video game by Valve Corporation. Two teams of five players compete against each other, with the goal of destroying the opponent team's Ancient, a guarded structure located within their bases. Each player controls a unique hero, which has distinct abilities and roles.

My own matches will be analysed in this project, with the main goal of understanding what factors improve my odds of winning. Most of the data is retrieved from the OpenDota API <https://docs.opendota.com/>. Extra data on hero attributes is scraped from a Dota 2 Wikipedia page <https://liquipedia.net/dota2/Hero_Roles>.

## Loading Data and Dependencies
```{r, message = FALSE, warning = FALSE}
# Loading libraries
library(tidyverse)
library(reshape2)
library(tibbletime)
library(scales)
library(stargazer)
library(glmnet)
library(caret)

# Set theme
theme_set(theme_minimal())

# Importing data
file.path <-"*"
hero <- read.csv(paste0(file.path, "dotahero.csv"), header = TRUE)
heroroles <- read.csv(paste0(file.path, "dotaheroroles.csv"), header = TRUE)
matches <- read.csv(paste0(file.path, "dotamatches.csv"), header = TRUE)
matchesinfo <- read.csv(paste0(file.path, "dotamatchesinfo.csv"), header = TRUE)
```

After loading all dependencies and all data, a small bit of cleanup still has to be done. 

Explanation of data frames imported:

- **hero**: Information on all heroes taken from OpenDota API

- **heroroles**: Hero attributes scraped from a Dota 2 Wikipedia page

- **matches**: Information on all matches I played taken from OpenDota API

- **matchesinfo**: IDs of all heroes on my team for all my matches taken from separate OpenDota API request

## Data Cleanup
```{r}
# Reordering
heroroles <- select(heroroles, 1,5,2,3,4,c(6:11))

# Finding missing heroes
print(hero$localized_name[!hero$localized_name %in% heroroles$Hero])

# Appending missing heroes
heroroles <- data.frame(Hero = c("Hoodwink", "Void Spirit", "Dawnbreaker", "Marci", "Primal Beast", "Muerta"),
Complexity = c(2, 2, 1, 2, 1, 1), Nuker = c(2, 2, 0, 0, 0, 2), 
Escape = c(2, 3, 0, 1, 0, 0), Carry = c(0, 2, 1, 1, 0, 3), 
Initiator = c(0, 0, 0, 2, 3, 0), Disabler = c(1, 1, 0, 1, 2, 1),
Durable = c(0, 0, 2, 0, 3, 0), Support = c(2, 0, 0, 1, 0, 0),
Pusher = c(0, 0, 0, 0, 0, 0), Jungler = c(0, 0, 0, 0, 0, 0)) %>%
rbind(heroroles, .)
```

The scraped heroroles data is not as updated as the hero attributes taken from OpenDota API. Six heroes are not present, thus their attributes are appended based on Dota 2's official website.

```{r, echo = FALSE}
# Sum of attributes by hero, excluding Complexity
heroroles$role.sum = rowSums(heroroles[,c(-1,-2)])

ggplot(heroroles, aes(role.sum)) + geom_histogram(binwidth = 0.5, fill = "#999999") + 
  labs(x = "Sum of hero role attributes", y = "Number of heroes")
```

```{r}
print(heroroles$Hero[which(heroroles$role.sum == 0)])
```

Hero attributes will be assessed to predict win rates. As such, heroes with more roles attributed to them will be weighted higher. A histogram of the sum of each heros' role attributes (excluding complexity) is plotted. 

A relatively wide distribution is seen, thus normalisation might have to be done to ensure equal weighting.

One value is 0, suggesting an error on the website. 

```{r}
# Appending Snapfire's attributes
heroroles <- heroroles[-which(heroroles$Hero == "Snapfire"),]
heroroles <- rbind(heroroles, list("Snapfire", 1, 0, 3, 1, 0, 1, 0, 1, 0, 0, 6))

# Changing Melee to binary
hero$Melee <- ifelse(hero$attack_type == "Melee", 1,0)
# Merging both tables
hero <- merge(hero, heroroles, by.x = "localized_name", by.y = "Hero")
# Removing unnecessary columns, renaming hero name
hero <- hero[, c(-3,-5,-17)] %>% rename(name = localized_name)
#Standardised hero role attributes
#standardhero <- hero %>% mutate_at(c(7:15), list(~./role.sum)) %>% .[,c(-3,-16)] %>% rename(name = localized_name)
```

The last faulty value is fixed. The Melee column is converted to binary since only melee and ranged are possible. Both tables are merged, with unnecessary columns removed.

```{r, echo = FALSE}
head(hero)
```

Explanation of variables in hero data:

- **name**: Name of the hero

- **id**: ID of the hero based on the OpenDota API

- **primary_attr**: An attribute that is either strength, intelligence or agility, which is hard to interpret without Dota knowledge

- **Melee**: 1 if the hero attacks with melee, and 0 if it is ranged
A higher number for the following attributes relates to a higher intensity:

- **Complexity**: Difficulty in playing a hero

- **Carry**: A hero that is weak at the start but scales and is strongest at the end

- **Nuker**: A hero that deals high amounts of burst damage in one go

- **Escape**: A hero that can escape getting killed

- **Initiator**: A hero that cripples many enemies to start a team fight

- **Disabler**: A hero that incapacitates enemies 

- **Durable**: A hero that can survive high amounts of damage

- **Support**: A hero supports allies and typically the carry, and is less dependent on gold and items

- **Pusher**: A hero that deals high amounts of damage to towers and structures

- **Jungler**: A hero that can kill neutral creeps in the "Jungle" between lanes

```{r}
# Merging both matches tables
matches <- merge(matches, matchesinfo, by = "match_id")
# Removing unnecessary columns, renaming hero ID
matches <- matches[, c(-1, -3, -4, -6, -7, -10, -14, -15, -16, -17)] %>% rename(ownheroID = hero_id)

# Converting to date and time
matches <- matches %>% mutate(start_time = as.POSIXct(start_time, origin = "1970-01-01 08:00:00")) %>% 
# Adding decimal hour
  mutate(start_hour = hour(start_time) + minute(start_time)/60 + second(start_time)/3600)
# Converting duration to minutes
matches$duration = matches$duration/60

head(matches)
```

The match information is retrieved from two types of API calls. They are first merged with unnecessary columns removed.

Time is given in UNIX time, thus it is converted to the right timezone in date and time. Decimal hours are also created for subsequent analysis. Duration is converted from seconds to minutes.

Explanation of variables in matches data:

- **win**: 1 if the match was won, and 0 if lost

- **duration**: Duration of the match in minutes

- **ownheroID**: ID of the hero I played

- **start_time**: Date and time when the match started

- **kills**: Number of enemy heroes I killed

- **deaths**: Number of times killed, mostly by enemy heroes

- **assists**: Number of times assisting a teammate in killing an enemy hero

- **heroID1 to heroID5**: IDs of all heroes in my team

- **start_hour**: Decimal hour when match started

## Data Exploration
```{r, echo = FALSE, message = FALSE}
# Making wins binary and melting data.
kda.df <- matches[,c(1,5:7)] %>% 
  mutate(win = ifelse(win == 1, "Win", "Loss")) %>% 
  melt(.) 
# Refactoring win to make win so that it comes first
kda.df$win <- factor(kda.df$win, levels = c("Win", "Loss"))

ggplot(kda.df, aes(x = variable, y = value, fill = win)) + geom_boxplot() + 
  labs(x = element_blank(), y = element_blank()) + 
  scale_fill_manual(values = c("#00BFC4", "#F8766D"))

```

The average kills and assists are higher while deaths are lower for wins. This is logical since kills and assists allow a player to get ahead in experience and gold, while deaths result in the opposite.

```{r, echo = FALSE, warning = FALSE}
# Grouping win rate and matches by duration
matches %>% group_by(group = cut(duration, seq(0, 100, by = 5), labels = seq(0, 95, by = 5))) %>% 
# If number of matches is less than 5, win rate is blank
  summarise(win_rate = ifelse(n()>5, sum(win)/n(),NA), matches = n()) %>%
# Making duration continuous
  type.convert(., as.is = TRUE) %>% 
  
  ggplot(., aes(x = group)) + 
  geom_col(aes(y = matches), fill = "#999999") + 
  geom_line(aes(y = win_rate*200, group = 1), colour = "#E69F00") + 
  scale_y_continuous(name = "Number of matches", sec.axis = sec_axis(~.*0.005, labels = percent, name = "Win rate (%)")) + 
  theme(axis.text.y.right = element_text(colour = "#E69F00")) +
  geom_vline(xintercept = mean(matches$duration), color = "red", linetype = "dashed") + 
  scale_x_continuous(breaks = seq(0, 100, by = 10)) + 
  labs(x = "Duration (min)")

```

The duration of a match follows a roughly normal distribution, with the mean at 43 minutes. The win rates for extreme durations are disregarded since they are heavily skewed. My win rate appears to be the best at around 20 minutes, suggesting that I may be good at closing matches off in the "early game" phase, gradually performing worse as the matches drag out. 

```{r, echo = FALSE}
# Grouping win rate and matches by hour of day
matches %>% group_by(group = cut(start_hour, seq(0, 24, by = 1), labels = seq(0, 23, by = 1))) %>% 
  summarise(win_rate = sum(win)/n(), matches = n()) %>% 
# Adding missing hours of day, so the gap is visible
  rbind(., data.frame(group = c(3:8), win_rate = rep(NA,6), matches = rep(0,6))) %>% 
# Making hour of day continuous
  type.convert(., as.is = TRUE) %>% 
  
  ggplot(., aes(x = group)) + 
  geom_col(aes(y = matches), fill = "#999999") + 
  geom_line(aes(y = win_rate*100, group = 1), colour = "#E69F00") + 
  scale_y_continuous(name = "Number of matches", sec.axis = sec_axis(~.*0.01, labels = percent, name = "Win rate (%)")) + 
  theme(axis.text.y.right = element_text(colour = "#E69F00")) + 
  scale_x_continuous(breaks = seq(0, 20, by = 4)) + 
  labs(x = "Hour of day")

```

Matches were often played in the evening. Interestingly, dinner breaks are also captured, as seen from the dip at 8 pm. There does not seem to be any clear trend in when I perform best. Apart from the anomalies at 2 and 8 am caused by small sample size, win rate fluctuates and hovers right above 50%, suggesting not a strong effect of time played on performance.

```{r, echo = FALSE, warning = FALSE}
#matches %>% group_by(group = cut(row_number(), seq(1, 1351, by = 50), labels = seq(50, 1350, by = 50), include.lowest = TRUE)) %>% summarise(win_rate = sum(win)/n()) %>% type.convert %>% ggplot(., aes(x = group, y= win_rate)) + geom_line()

#matches %>% group_by(group = cut(row_number(), seq(1, 1401, by = 100), labels = seq(50, 1400, by = 100), include.lowest = TRUE)) %>% summarise(win_rate = sum(win)/n()) %>% type.convert %>% ggplot(., aes(x = group, y= win_rate)) + geom_line()

# Rolling win rate function
rolling_win_rate <- rollify(~sum(.x)/100, window = 100)

# Last two matches not selected since they are two years after and skews data
matches[c(1:1335),] %>%
# Adding win rate, match number and year
  mutate(win_rate = rolling_win_rate(win), matches = c(1:1335), year = year(start_time)) %>% 
  
  ggplot(., aes(x = matches, y = win_rate, colour = year)) + 
  geom_line() + 
  scale_colour_gradient(low = "#0054cc", high = "#90cc00") + 
  scale_y_continuous(labels = percent_format(accuracy = 1)) + 
  labs(y = "100-match rolling win rate (%)", x = "Matches played")

#+ scale_colour_gradient2(low = "red", high = "blue", mid = "white", midpoint = 2017, limit = c(2014,2020))
```

The majority of my matches were played from 2014 to 2015, where the rolling win rate often stayed above the 50% mark. Much fewer matches were played between 2016 and 2020, with the win rate dropping dramatically, likely due to a lack of consistent gaming.

```{r}
herowinrates <- matches %>% group_by(ownheroID) %>% 
# Grouping by win rate, wins, matches by hero 
  summarise(win_rate = sum(win)/n(), win = sum(win), matches = n()) %>% 
# Adding hero name
  merge(., hero[,c(1,2)], by.x = "ownheroID", by.y = "id") %>% 
# Adding p-value  
  mutate(p.value = apply(., MARGIN = 1, function(i){
    binom.test(as.integer(i[3]), as.integer(i[4]), 0.5, alternative = "two.sided")$p.value})) %>% 
  .[order(.$p.value),]

```

Since the matches played and win rate per hero varies greatly, a two-tailed binomial test is conducted for each hero assuming a win rate of 50% to account for both variables. P-values for an alternative hypothesis of a win rate  than 50% are obtained.

```{r, echo = FALSE}
#check after knitting
#Choosing win rates above 50%
which(herowinrates$win_rate > 0.5)[c(1:10)] %>% 
  herowinrates[.,] %>% 
  ggplot(., aes(x = reorder(name, -p.value), y = win_rate, fill = matches)) + 
  geom_col(width = 0.2) + 
  scale_fill_gradient(low = "#d0d1e6", high = "#0155b6", name = "Matches\nplayed") + 
  scale_y_continuous(labels = percent_format(accuracy = 1)) + 
  labs(x = "Increasing P-value", y = "Win rate (%)")  + 
  ggtitle("Heroes with best win rate") +
  coord_flip(ylim = c(0, 1), xlim = c(1, 10), clip="off") + 
  annotate("segment", x = 6.5, xend = 4.5, y = -0.245, yend = -0.245, arrow=arrow(length=unit(0.2, "cm")))

#Choosing win rates below 50%
which(herowinrates$win_rate < 0.5)[c(1:5)] %>% 
  herowinrates[.,] %>% 
  ggplot(., aes(x = reorder(name, -p.value), y = (1 - win_rate), fill = matches)) + 
  geom_col(width = 0.2) + 
  scale_fill_gradient(low = "#e6d1d0", high = "#b60134", name = "Matches\nplayed") + 
  scale_y_continuous(labels = percent_format(accuracy = 1)) + 
  labs(x = "Increasing P-value", y = "Loss rate (%)")  + 
  ggtitle("Heroes with worst win rate") +
  coord_flip(ylim = c(0, 1), xlim = c(1, 5), clip="off") + 
  annotate("segment", x = 3.25, xend = 2.25, y = -0.245, yend = -0.245, arrow=arrow(length=unit(0.2, "cm")))

```

Based on p-values, the top three heroes I should choose to win are Necrophos, Queen of Pain and Ember spirit since they have the highest probabilities of having a more than average win rate. On the other hand, I should not choose Rubick, Bounty Hunter and Huskar.


```{r}
matches <- merge(matches, hero, by.x = "ownheroID", by.y = "id")
```

Each hero has a specific list of attributes. These can be matched back to the matches I played to generate more variables. These can then be analysed with a correlation matrix.

```{r, echo = FALSE}
# Correlation matrix calculated with relevant columns
cor(matches[,c(2,3,5:7,16:26)]) %>% 
  melt(.) %>% 
  ggplot(., aes(x = Var1, y = Var2, fill = value)) + 
  geom_tile(color = "white") + 
  scale_fill_gradient2(low = "red", high = "blue", mid = "white", midpoint = 0, limit = c(-1,1), space = "Lab", name="Pearson\nCorrelation") + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1), axis.title.x = element_blank(), axis.title.y = element_blank()) + 
  coord_fixed()
```

A blue colour represents a higher positive correlation between the two corresponding variables. Red represents the opposite.

The original match data is at the bottom-left corner. Kills and assists are the most positively correlated with wins while deaths are negatively correlated, in line with the analysis above. The duration of the match has likely little effect on the win rate.

The additional attributes of heroes I played are represented on the top-right side. For example, the Initiator and Disabler attributes are fairly strongly correlated, which makes sense when considering heroes that can initiate team fights normally do so by "disabling" the opponent.

Other interesting correlations include the slight positive correlation between Carry and win, suggesting that I may have a higher chance at winning if I pick a hero with a high Carry attribute. 

## Predicting Match Outcomes
```{r}
# First loops through the hero attributes
matchesbyroles <- sapply(hero[,c(4:14)], function(i){
# Next, loops through each of the five hero IDs in matches for the attribute
  sapply(matches[,c(8:12)], function(n){
# Matches the IDs with the relevant attributes
    i[match(n, hero$id)]}) %>% 
# Sums the relevant attributes
    rowSums()}) %>% 
  as.data.frame() %>% cbind(win = matches$win, .) %>% 
# Converting binary wins to text
  mutate(win = ifelse(win == 1, "Win", "Loss") %>% 
# Converting wins to factor type
           as.factor(.))
```

A good set of hero picks in a team is important in deciding who wins. It is thus useful to see whether my team's hero picks can be used to predict wins and losses. The hero attributes are matched for each hero in the team, and summed as a gauge of the team composition.

```{r, echo = FALSE, message = FALSE}
matchesbyroles %>% melt(.) %>% 
  group_by(win, variable) %>% 
# Grouping by win/loss, and calculating mean and a +/- 1 SD range
  summarise(vmin = mean(value) - sd(value), vmean = mean(value), vmax = mean(value) + sd(value)) %>% 

  ggplot(., aes(x = variable, y = vmean, ymin = vmin, ymax = vmax, colour = win)) + 
  geom_pointrange(position=position_dodge(width=0.5)) + 
  labs(x = element_blank(), y = element_blank()) + 
  coord_flip() + 
  scale_colour_discrete(breaks = c("Win", "Loss"))
```

Since the summed hero attributes are discrete variables with a small range, a mean plot is made with a +/- one standard deviation range. The difference in magnitude between each variable is not very significant, considering the summed hero attributes for each attribute is not equal. For example, each hero needs to have at least a complexity of one, which is not a requirement for other values. This results in complexity having the highest magnitude.

Comparing the hero attribute composition between winning and losing matches, little differences are seen apart for the deviation in complexity, Initiator and Escape. A higher value for these attributes might result in a higher chance of losing, but a multiple logistic regression model is more useful in accurately analysing this.

```{r}
set.seed(1)

# Setting 10-fold cross-validation
train_control <- trainControl(method = "cv", number = 10)

# Conducting regression tests
roles.model <- train(win ~ ., data = matchesbyroles, method = "glm", family = binomial, trControl = train_control)
```

```{r, echo = FALSE, results = "asis"}
# Generating call parameter for stargazer
roles.model.glm = glm(win ~ ., family = binomial, data = matchesbyroles)
roles.model$finalModel$call = roles.model.glm$call

stargazer(roles.model$finalModel,
          type = "html", 
          single.row = TRUE, 
          dep.var.labels  = "Increase in probability of win",
          dep.var.caption   = "Hero roles logistic regression model", 
          omit.stat = c("LL", "aic"), 
          add.lines = list(c("Accuracy", round(as.numeric(roles.model$results[2]),3)),
                           c("Kappa", round(as.numeric(roles.model$results[3]),4))))
```

The multiple logistic regression model with 10-fold cross validation suggests that only the complexity attribute is useful in predicting the win rate. A higher complexity attributes suggests that a team picked heroes that were difficult to play with, resulting in a lower chance of winning if incompetent. The other factors were rather insignificant in predicting the win rate.

The accuracy of the model, the probability that the model is able to predict the right winning outcome, is rather low. Perhaps another model is more useful in predictions.

```{r}

# First loops through each hero ID
matchesbyheroes <- lapply(hero$id, function(i){
# Next, loops through each of the five heroes for each match checking for the hero ID
  apply(ifelse(matches[,c(8:12)] == i,1,0), MARGIN = 1, sum)}) %>% 
  as.data.frame() %>%
# Adding back hero names, but replacing space with _
  setNames(gsub(" ","_",hero$name)) %>% 
# Removing heroes that do not appear in any matches
  .[,-c(which(colMeans(.) == 0))] %>% 
  cbind(win = matches$win, .) %>%
# Relabels win variable to string
  mutate(win = ifelse(win == 1, "Win", "Loss") %>%
# Converting wins to factor type
                        as.factor(.))
```

Instead of trying to predict wins by the attributes of heroes played, the heroes played themselves can be used for prediction. There is one column for each hero, stating whether the hero was picked for each match, along with whether the match was a win or loss. 

```{r, warning = FALSE}
set.seed(1)

# Retrieving original glm model info
glm_wo_intercept <- getModelInfo("glm",regex=FALSE)[[1]]
glm_wo_intercept$fit <- function (x, y, wts, param, lev, last, classProbs, ...) 
{
    dat <- if (is.data.frame(x)) 
        x
    else as.data.frame(x, stringsAsFactors = TRUE)
    dat$.outcome <- y
    if (length(levels(y)) > 2) 
        stop("glm models can only use 2-class outcomes")
    theDots <- list(...)
    if (!any(names(theDots) == "family")) {
        theDots$family <- if (is.factor(y)) 
            binomial()
        else gaussian()
    }
    if (!is.null(wts)) 
        theDots$weights <- wts
# modelArgs is changed from outcome ~ . to outcome ~ 0+., which essentially removes the intercept
    modelArgs <- c(list(formula = as.formula(".outcome ~ 0+."), 
        data = dat), theDots)
    out <- do.call("glm", modelArgs)
    out$call <- NULL
    out
}

# Conducting regression tests, with 10-fold cross validation
heroes.model <- train(win ~ ., data = matchesbyheroes, method = glm_wo_intercept, family = binomial, trControl = train_control)
```

The intercept of the model is removed since the data set suffers from the dummy variable trap (the last hero in a match can always be determined since every match has exactly five heroes). 

```{r, echo = FALSE, results = "asis"}
# Generating call parameter for stargazer
heroes.model.glm = glm(win ~ ., family = binomial, data = matchesbyheroes)
heroes.model$finalModel$call = heroes.model.glm$call

# Getting most important heroes
varImp.heroes <- varImp(heroes.model)[["importance"]] %>%
# Reordering based on importance
  .[order(.$Overall, decreasing = TRUE),, drop = FALSE]
# Saving 20 most important heroes
mostImp.heroes <- rownames(varImp.heroes)[1:20]

stargazer(heroes.model$finalModel, 
          type = "html", 
          single.row = TRUE, 
          dep.var.labels  = "Increase in probability of win",
          dep.var.caption   = "Heroes logistic regression model", 
          omit.stat = c("LL", "aic"), 
          keep = mostImp.heroes, 
          order = mostImp.heroes, 
          add.lines = list(c("Accuracy", round(as.numeric(heroes.model$results[2]),3)),
                           c("Kappa", round(as.numeric(heroes.model$results[3]),4))))
```

For the sake of brevity, only the most important heroes for the model are shown. Unfortunately, the accuracy of this model is also not significantly better than when using hero role attributes as variables.

## Conclusion
Analysis of my matches already reveals some interesting insights on how I perform in my games. Statistics on the hero attributes also serve as a rough gauge of how a normal Dota 2 match at my matchmaking rating is like on a broader scale. However, predicting matches based on the hero picks of my team is still a challenge looking at the low level of accuracy from the regression models. Some factors that contribute to the low accuracy could be the small data set and simplicity of models. Nonetheless, the data set had sufficient samples and variables for  trends and patterns to be extracted as a Exploratory Data Analysis (EDA) project.